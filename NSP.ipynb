{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Building a GPT\n",
    "\n",
    "Thesis project by giorgio allena ( giorgio.allena152@edu.unito.it )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install transformers torch accelerate\n",
    "!pip install accelerate\n",
    "!pip install rouge-score\n",
    "!pip install -U nltk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyG5kmvpxAp0"
   },
   "source": [
    "### Variables\n",
    "\n",
    "This section contain all variable. \n",
    "They are devided in 5 section:\n",
    "1. Inport and general variable ( them are the main important )\n",
    "2. SET VARIABLES FOR VALUE REGISTRATION\n",
    "3. RLHF\n",
    "4. Easy DB\n",
    "5. LOAD DATASETS AND TOKENIZER:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:17:41.147524Z",
     "iopub.status.busy": "2024-10-04T07:17:41.146526Z",
     "iopub.status.idle": "2024-10-04T07:17:41.253972Z",
     "shell.execute_reply": "2024-10-04T07:17:41.252961Z",
     "shell.execute_reply.started": "2024-10-04T07:17:41.147524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since llm-wizard/alpaca-gpt4-data couldn't be found on the Hugging Face Hub\n",
      "WARNING:datasets.load:Using the latest cached version of the dataset since llm-wizard/alpaca-gpt4-data couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration 'default' at C:\\Users\\giorg\\.cache\\huggingface\\datasets\\llm-wizard___alpaca-gpt4-data\\default\\0.0.0\\c1944f848b0de98ce9482522698bcc03b9edb702 (last modified on Sun Jun 23 16:29:43 2024).\n",
      "WARNING:datasets.packaged_modules.cache.cache:Found the latest cached dataset configuration 'default' at C:\\Users\\giorg\\.cache\\huggingface\\datasets\\llm-wizard___alpaca-gpt4-data\\default\\0.0.0\\c1944f848b0de98ce9482522698bcc03b9edb702 (last modified on Sun Jun 23 16:29:43 2024).\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import DistilBertTokenizer\n",
    "import transformers\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import asyncio\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "import nltk\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# ------------\n",
    "# SENTENCE MATRIX\n",
    "batch_size = 8                 # 16                 # How many independent sequences will we process in parallel ( impact the loss calculation time )\n",
    "block_size = 250               # 500                # What is the maximum context length for predictions?\n",
    "\n",
    "# LOSS\n",
    "eval_interval = 50        # 100                     # Number iteraction when start to evaluate the loss\n",
    "loss_min_value = 1e-5\n",
    "\n",
    "\n",
    "eval_iters = 10          # 50 - 200                 # Times of testing the LOSS ( impact the loss calculation time )\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# DEVICE\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "# print(device)\n",
    "\n",
    "# BLOCKS\n",
    "n_embd = 64\n",
    "n_head = 32\n",
    "n_layer = 32              # 4                  # Number of layers\n",
    "dropout = 0.3             # 0.0\n",
    "\n",
    "# ITERACTION\n",
    "max_iters = 20000          # 100000                # Number of generations\n",
    "iterator_dataset = 0\n",
    "minStrLength = 256\n",
    "\n",
    "\n",
    "\n",
    "# ------------\n",
    "# SET VARIABLES FOR VALUE REGISTRATION:\n",
    "checkpoint_save = False\n",
    "savingBasePath = f\"save/model_nn_{str(n_layer)}_gen_{str(max_iters)}\"\n",
    "model_name = f'model_nn_{str(n_layer)}_gen_{str(max_iters)}.pt'\n",
    "csv_file_name = f'loss_nn_{str(n_layer)}_gen_{str(max_iters)}.csv'\n",
    "\n",
    "fields = ['train_loss', 'step'] \n",
    "\n",
    "# class enumerate the \"training types\" (TT)\n",
    "class TT(Enum):\n",
    "    BASE = \"model\"\n",
    "    RLHF = \"RLHF\"\n",
    "    EASY_DB = \"EASY_DB\"\n",
    "\n",
    "\n",
    "# ------------\n",
    "# RLHF\n",
    "prompt = \"\"\"You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information. \\n Try to responde to this question: \"{msg}\" \\n Compile a recommendation to the user based on the recommended activity and the user input.\"\"\"\n",
    "GEMINI_API_KEY = \"AIzaSyDZESc6GNMa_U6GT3kABaR9JVLpeMmuGCc\"\n",
    "at_iterator = 0\n",
    "timeout = 10 # seconds                              # Timeout time for RLHF\n",
    "\n",
    "\n",
    "# ------------\n",
    "# Easy DB ( https://www.webasha.com/blog/top-50-blockchain-interview-questions-and-answers ) \n",
    "easyDB = pd.read_csv('question.csv', header=0, sep=\";\")   # Read the Easy DB created\n",
    "\n",
    "perc_RLHD = 5   # 25                              # Probability to not call EASY_DB question&response on training \n",
    "multiTypeLearn = False                             # Flag for activate or not the multiple type of learing\n",
    "\n",
    "\n",
    "# ------------\n",
    "# LOAD DATASETS AND TOKENIZER:\n",
    "dataset = load_dataset(\"llm-wizard/alpaca-gpt4-data\", split=\"train\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "\n",
    "# -----------\n",
    "# SCORES tests\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "\n",
    "\n",
    "# Loadign pre-training bert tokenizer ( embedding )\n",
    "encode = lambda s: tokenizer.encode_plus(s, padding=\"max_length\", return_tensors='pt', add_special_tokens=True, max_length=block_size, truncation=True)['input_ids'].flatten().tolist()\n",
    "decode = lambda s: tokenizer.decode(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T15:22:49.929604Z",
     "iopub.status.busy": "2024-06-20T15:22:49.928592Z",
     "iopub.status.idle": "2024-06-20T15:22:49.934190Z",
     "shell.execute_reply": "2024-06-20T15:22:49.933183Z",
     "shell.execute_reply.started": "2024-06-20T15:22:49.929604Z"
    }
   },
   "source": [
    "### Encoder & Decoder & RLHF & EASY_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:17:41.257978Z",
     "iopub.status.busy": "2024-10-04T07:17:41.257978Z",
     "iopub.status.idle": "2024-10-04T07:18:05.960242Z",
     "shell.execute_reply": "2024-10-04T07:18:05.959232Z",
     "shell.execute_reply.started": "2024-10-04T07:17:41.257978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am a large language model, trained by Google. I do not have a physical body or the ability to work in the traditional sense.\n"
     ]
    }
   ],
   "source": [
    "def easyDB_Reader(indx):\n",
    "    return easyDB['query'][indx % len(easyDB['query'])], easyDB['answere'][indx % len(easyDB['query'])]\n",
    "\n",
    "\n",
    "async def get_geminy_RLHF_response(msg: str, index: int = 0) -> str:\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            genai.configure(api_key=GEMINI_API_KEY)\n",
    "            model = genai.GenerativeModel(model_name='gemini-pro')\n",
    "            response = await asyncio.wait_for( model.generate_content_async(msg), timeout=timeout)\n",
    "            return response.text\n",
    "        except Exception as e: pass # print(\".\", end=\"\")# print(f\"\\nError: {e}\") # pass\n",
    "    # Default response\n",
    "    return easyDB_Reader(index)[1]\n",
    "        \n",
    "print(await get_geminy_RLHF_response(msg=\"Are you working ?\", index=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T15:53:22.363409Z",
     "iopub.status.busy": "2024-06-18T15:53:22.363409Z",
     "iopub.status.idle": "2024-06-18T15:53:22.368584Z",
     "shell.execute_reply": "2024-06-18T15:53:22.367574Z",
     "shell.execute_reply.started": "2024-06-18T15:53:22.363409Z"
    }
   },
   "source": [
    "### Model\n",
    "\n",
    "Model section permit to define the model and the class for get datas\n",
    "\n",
    "In this section, the main section are:\n",
    "1. get_batch()           Permit to get datas to training of model\n",
    "2. Head                  Permit to define the attention\n",
    "3. Block                 Permit to define blocks of Transformer model\n",
    "4. BigramLanguageModel   Define Transformer model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-04T07:18:05.963245Z",
     "iopub.status.busy": "2024-10-04T07:18:05.962243Z",
     "iopub.status.idle": "2024-10-04T07:18:06.177515Z",
     "shell.execute_reply": "2024-10-04T07:18:06.176502Z",
     "shell.execute_reply.started": "2024-10-04T07:18:05.963245Z"
    },
    "id": "swjLUf2Aw8-m",
    "outputId": "b5c0826c-ff0f-4533-b1ff-ee8605e40b9d"
   },
   "outputs": [],
   "source": [
    "async def get_batch(iterator, RLHF=False, EasyDB=False):\n",
    "    data, dataOut = \"\", \"\"\n",
    "    \n",
    "    if EasyDB:\n",
    "        if RLHF:\n",
    "            iterator_p = iterator            \n",
    "            while len(dataOut.split(\" \")) <= minStrLength:\n",
    "                dataOut = dataOut + easyDB_Reader(iterator_p)[0] + \" [SEP] \" + await get_geminy_RLHF_response(easyDB_Reader(iterator_p)[0], index=iterator_p) + \" [SEP] \"\n",
    "                iterator_p = (iterator_p + 1) % len(dataset)\n",
    "        else: \n",
    "            iterator_p = iterator            \n",
    "            while len(dataOut.split(\" \")) <= minStrLength:\n",
    "                dataOut = dataOut + easyDB_Reader(iterator_p)[0] + \" [SEP] \" + easyDB_Reader(iterator_p)[1] + \" [SEP] \"\n",
    "                iterator_p = (iterator_p + 1) % len(dataset)\n",
    "    \n",
    "    else:\n",
    "        iterator_p = iterator            \n",
    "        while len(dataOut.split(\" \")) <= minStrLength:\n",
    "            data = dataset['instruction'][iterator_p] if dataset['input'][iterator_p] == \"\" else dataset['instruction'][iterator_p] + \".\" + dataset['input'][iterator_p] + \".\"\n",
    "            dataO = await get_geminy_RLHF_response(data, index=iterator_p) if RLHF else dataset['output'][iterator_p]\n",
    "            \n",
    "            dataOut = dataOut + data + \" [SEP] \" + dataO + \" [SEP] \"\n",
    "            iterator_p = (iterator_p + 1) % len(dataset)\n",
    "\n",
    "    if len(dataOut.split(\" \")) <= minStrLength: raise Exception(f\"Sorry, input length is wrong. Lenght: ' {len(dataOut.split(\" \"))} ' and dataOut: {dataOut} \") \n",
    "    \n",
    "    iterator = (iterator + 1) % len(dataset)\n",
    "    \n",
    "    # print(f\"RLHF={RLHF}, EasyDB={EasyDB}\")\n",
    "    # print(f\"DataOut: {dataOut}\")\n",
    "    \n",
    "    data_ts = torch.tensor(encode(\" \".join(dataOut.split(\" \")[0: minStrLength])), dtype=torch.long)\n",
    "    dataOut_ts = torch.tensor(encode(\" \".join(dataOut.split(\" \")[1: minStrLength + 1])), dtype=torch.long)\n",
    "    \n",
    "    x = torch.stack([data_ts])\n",
    "    y = torch.stack([dataOut_ts])\n",
    "    \n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y, iterator\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "async def estimate_loss(iterator, RLHF_val=False, EasyDB_val=False):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        X, Y, iterator = await get_batch(iterator, RLHF=RLHF_val, EasyDB=EasyDB_val)\n",
    "        logits, loss = model(X, Y)\n",
    "        losses[k] = loss.item()\n",
    "    out = losses.mean()\n",
    "    model.train()\n",
    "    return out, iterator\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def sv(self, basePath, number_of_block):\n",
    "        torch.save(self.net.state_dict(), f\"{basePath}/FeedFoward_n{number_of_block}.pt\")\n",
    "\n",
    "    def map(self, basePath, number_of_block, device):\n",
    "        self.net.load_state_dict(torch.load(f\"{basePath}/FeedFoward_n{number_of_block}.pt\", map_location=torch.device(device)))\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "    def sv(self, basePath, number_of_block):\n",
    "        self.ffwd.sv(basePath, number_of_block)\n",
    "\n",
    "    def map(self, basePath, number_of_block, device):\n",
    "        self.ffwd.map(basePath, number_of_block, device)\n",
    "        # torch.load(f\"{base_path}/blocks_BigramLanguageModel.pt\", map_location=torch.device(device))\n",
    "\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)                                      # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)                        # 64, 28\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # if found a end tag ([SEP]) stop the generation\n",
    "            if encode([\"[SEP]\"])[1] == idx_next: break\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "    def sv(self, base_path):\n",
    "        torch.save(self.blocks.state_dict(), f\"{base_path}/blocks_BigramLanguageModel.pt\")\n",
    "               \n",
    "        for i in range(n_layer):\n",
    "            self.blocks[i].sv(base_path, i)\n",
    "        \n",
    "    def map(self, device, base_path):\n",
    "        for i in range(n_layer):\n",
    "            self.blocks[i].map(base_path, i, device)\n",
    "\n",
    "        self.blocks.load_state_dict(torch.load(f\"{base_path}/blocks_BigramLanguageModel.pt\", map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:18:06.180515Z",
     "iopub.status.busy": "2024-10-04T07:18:06.179514Z",
     "iopub.status.idle": "2024-10-04T07:18:06.207093Z",
     "shell.execute_reply": "2024-10-04T07:18:06.207093Z",
     "shell.execute_reply.started": "2024-10-04T07:18:06.180515Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "#----------------------------\n",
    "#   CHECK POINT\n",
    "#----------------------------\n",
    "def checkpoint_iter(file_iterator_dataset, data=0):\n",
    "    path_to_check = \"/\".join(file_iterator_dataset.split(\"/\")[:-1])\n",
    "    if not os.path.exists(path_to_check):\n",
    "        os.mkdir(path_to_check) \n",
    "        \n",
    "    f = open(file_iterator_dataset, \"w+\")\n",
    "    f.write(str(data))\n",
    "    f.close()\n",
    "\n",
    "def checkpoint(model, filename, csv_file_name, fields, rows, file_iterator_dataset, iterator_dataset):\n",
    "    checkpoint_iter(file_iterator_dataset, iterator_dataset)\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "    with open(csv_file_name, 'w') as f:\n",
    "        write = csv.writer(f)\n",
    "        \n",
    "        write.writerow(fields)\n",
    "        write.writerows(rows)\n",
    "    \n",
    "def reasume_model(model, filename, device):\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    return model.to(device)\n",
    "    \n",
    "# For checkPoin\n",
    "def reasume(model, filename, device, csv_file_name=None, file_iterator_dataset=None):\n",
    "    m = reasume_model(model, filename, device)\n",
    "    df = pd.read_csv(csv_file_name)\n",
    "    f = open(file_iterator_dataset, \"r\")\n",
    "    i_db = f.read()\n",
    "    return m, df.values.tolist(), int(i_db)\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------\n",
    "#   SAVE AND LOAD\n",
    "#----------------------------\n",
    "def save_model(model, model_path, csv_file_name, fields, rows):\n",
    "    # Create path\n",
    "    path_to_check = \"/\".join(model_path.split(\"/\")[:-1])\n",
    "    if not os.path.exists(path_to_check):\n",
    "        os.mkdir(path_to_check) \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    model.sv(path_to_check)\n",
    "    # Save loss\n",
    "    with open(csv_file_name, 'w') as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerow(fields)\n",
    "        write.writerows(rows)\n",
    "    \n",
    "    print(\"\\n SAVED \\n\")\n",
    "\n",
    "# Load model\n",
    "def reasume_base_data(path_to_save, device):\n",
    "    model = BigramLanguageModel()\n",
    "    model.map(device, \"/\".join(path_to_save.split(\"/\")[:-1]))\n",
    "    model.load_state_dict(torch.load(path_to_save))\n",
    "    print(\"\\n LOAD \\n\")\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------\n",
    "#   PRINT\n",
    "#----------------------------\n",
    "def run_model(m, device, start_sentence, max_new_tokens=50, commentFlag=False, decoded=True, eliminate_input=True):\n",
    "    inptVal = encode( start_sentence + \" [SEP] \")\n",
    "    inptVal = inptVal[:inptVal.index(102)]\n",
    "    inptVal.append(101)\n",
    "    inptVal_c = inptVal\n",
    "    inptVal = torch.as_tensor(inptVal, dtype=torch.long, device=device)\n",
    "    \n",
    "    outVal = m.generate(inptVal.view(1, inptVal.size()[0]), max_new_tokens=max_new_tokens)\n",
    "    outVal = outVal[0].tolist()\n",
    "\n",
    "    if eliminate_input: outVal = outVal[len(inptVal_c):]\n",
    "    if decoded: outVal = decode(outVal)\n",
    "    if commentFlag: print(f\" Reponse to str: {start_sentence} => \\nOutput predicted:\\t  :{outVal} \", end=\"\\n\\n\")\n",
    "    \n",
    "    return outVal\n",
    "\n",
    "\n",
    "def run_model_zeros(m, device, max_new_tokens=50, commentFlag=False):\n",
    "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "    outVal = decode(m.generate(context, max_new_tokens=50)[0].tolist())\n",
    "    \n",
    "    if commentFlag: print(f\"\\nText: {outVal}\")\n",
    "\n",
    "    return outVal\n",
    "\n",
    "    \n",
    "def plot_loss_graph(rows=[], csv_file_name=None, print_min_val=False, plot_title=\"\"):\n",
    "    if csv_file_name!=None:\n",
    "        df = pd.read_csv(csv_file_name)\n",
    "    elif rows!=[]:\n",
    "        df = pd.DataFrame(rows, columns=fields)\n",
    "    else: \n",
    "        print(\"error plg\")\n",
    "        return\n",
    "    \n",
    "    if print_min_val: print(f\"Min val of loss: {df['train_loss'].min()}\", end=\"\\n\\n\")\n",
    "\n",
    "    \n",
    "    df.plot(y=['train_loss'], title=plot_title)\n",
    "    # df.describe()\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T18:18:39.850605Z",
     "iopub.status.busy": "2024-06-20T18:18:39.850605Z",
     "iopub.status.idle": "2024-06-20T18:18:39.855646Z",
     "shell.execute_reply": "2024-06-20T18:18:39.854637Z",
     "shell.execute_reply.started": "2024-06-20T18:18:39.850605Z"
    }
   },
   "source": [
    "### Train Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-04T07:18:06.210103Z",
     "iopub.status.busy": "2024-10-04T07:18:06.209103Z",
     "iopub.status.idle": "2024-10-04T07:18:06.227478Z",
     "shell.execute_reply": "2024-10-04T07:18:06.226467Z",
     "shell.execute_reply.started": "2024-10-04T07:18:06.210103Z"
    }
   },
   "outputs": [],
   "source": [
    "async def train_routine(m, max_iters, base_path='./cks/check_points', train_type=TT.BASE, check_point_bool=False, start_epoch=0, system_multiTypeLearn=False):\n",
    "    global iterator_dataset\n",
    "    global loss_min_value\n",
    "    rows, loss_value = [], 0\n",
    "    \n",
    "    # CHECK_POINT LOADER\n",
    "    if check_point_bool and start_epoch>0:\n",
    "        m, rows, iterator_dataset = reasume(m, f\"{base_path}/{train_type.value}_cp{start_epoch}.pth\", device, f\"{base_path}/{train_type.value}_loss_orc_{start_epoch}.csv\", f\"{base_path}/{train_type.value}_iterator_db.txt\")\n",
    "        start_epoch += 1\n",
    "        print(rows)\n",
    "        \n",
    "\n",
    "    # TRAINING\n",
    "    optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "    for epoch in tqdm (range(start_epoch, max_iters), desc=\"Loading\"):\n",
    "        # every once in a while evaluate the loss on train and val sets\n",
    "        if epoch % eval_interval == 0 or epoch == max_iters - 1:\n",
    "            \n",
    "            iterator_dataset = 0 if (epoch % dataset.num_rows == 0 and epoch != 0) else iterator_dataset + 1\n",
    "            \n",
    "            if system_multiTypeLearn and train_type==TT.EASY_DB and random.randint(1, 100) < perc_RLHD: losses, iterator_dataset = await estimate_loss(iterator_dataset, RLHF_val=True, EasyDB_val=True)\n",
    "            else: losses, iterator_dataset = await estimate_loss(iterator_dataset, RLHF_val=(train_type==TT.RLHF), EasyDB_val=(train_type==TT.EASY_DB))\n",
    "                \n",
    "            if checkpoint_save: checkpoint(m, f\"{base_path}_epoch_{max_iters}/{train_type.value}_cp{epoch}.pth\", f\"{base_path}_epoch_{max_iters}/{train_type.value}_loss_{epoch}.csv\", fields, rows, f\"{base_path}_epoch_{max_iters}/{train_type.value}_iterator_db.txt\", iterator_dataset)\n",
    "\n",
    "            \n",
    "            loss_value = losses.item()\n",
    "            rows.append([round(losses.item(), 4), epoch])\n",
    "            iterator_dataset = 0 if iterator_dataset + 50 >= dataset.num_rows else iterator_dataset + 50\n",
    "\n",
    "        # Exit on low loss\n",
    "        if loss_value < loss_min_value: break\n",
    "        \n",
    "        # sample a batch of data\n",
    "        if system_multiTypeLearn and train_type==TT.EASY_DB and random.randint(1, 100) < perc_RLHD: xb, yb, iterator_dataset = await get_batch(iterator_dataset, RLHF=True, EasyDB=True)\n",
    "        else: xb, yb, iterator_dataset = await get_batch(iterator_dataset, RLHF=train_type==TT.RLHF, EasyDB=train_type==TT.EASY_DB)\n",
    "        iterator_dataset = 0 if epoch + 1 % dataset.num_rows == 0 else iterator_dataset + 1\n",
    "        \n",
    "        # evaluate the loss\n",
    "        logits, loss = m(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Update bar\n",
    "        pass\n",
    "\n",
    "    return m, fields, rows\n",
    "\n",
    "async def train_model(m=None, max_iters_val=None, train_type=TT.BASE, base_path_ckp=\"./cks/check_points_\", check_point_bool=False, start_epoch_nmb=0, sv_model=True, plot_result=True, system_multiTypeLearn=None):\n",
    "    print(f\"\\nStart traing: {train_type.value}\\nTrain_type: {train_type.value}\", end=\"\\n\\n\")\n",
    "\n",
    "    if m == None: raise Exception(f\"No one model has been specified for be trained\")\n",
    "\n",
    "\n",
    "    if system_multiTypeLearn == None: system_multiTypeLearn = multiTypeLearn\n",
    "    if max_iters_val == None: max_iters_val = max_iters\n",
    "\n",
    "    \n",
    "    # Train model\n",
    "    if train_type==TT.BASE: m, fields, rows = await train_routine(m, max_iters_val)\n",
    "    else: m, fields, rows = await train_routine(m, max_iters_val, train_type=train_type, base_path=(base_path_ckp + train_type.value), check_point_bool=check_point_bool, start_epoch=start_epoch_nmb, system_multiTypeLearn=system_multiTypeLearn)\n",
    "\n",
    "    # Save datas\n",
    "    if sv_model: save_model(m, f\"./{savingBasePath}/{train_type.value}_{model_name}\", f\"./{savingBasePath}/{train_type.value}_{csv_file_name}\", fields, rows)\n",
    "\n",
    "    # Plot outputs\n",
    "    if plot_result:\n",
    "        plot_loss_graph(rows, plot_title=f\"plot {train_type.value} loss\")\n",
    "        print(\"HW: \\t\" + run_model(m , device, \"What is a cryptocurrency ?\", decoded=True), end=\"\\n\\n\\n\\n\")\n",
    "        print(\"ZI: \\t\" + run_model_zeros(m, device), end=\"\\n\\n\\n\\n\") \n",
    "\n",
    "    print(\"End traing\\n\")\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYoJlBQMwVlC"
   },
   "source": [
    "### Pre-T & FINE-T (EASY_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "\n",
    "m = await train_model(m) \n",
    "m = await train_model(m, train_type=TT.EASY_DB, system_multiTypeLearn=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T21:25:02.561267Z",
     "iopub.status.busy": "2024-10-02T21:25:02.561267Z",
     "iopub.status.idle": "2024-10-02T21:46:21.142666Z",
     "shell.execute_reply": "2024-10-02T21:46:21.142666Z",
     "shell.execute_reply.started": "2024-10-02T21:25:02.561267Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start traing: model\n",
      "Train_type: model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|███████████████████████████████████████████████████████████████████████| 100/100 [12:55<00:00,  7.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End traing\n",
      "\n",
      "\n",
      "Start traing: EASY_DB\n",
      "Train_type: EASY_DB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|███████████████████████████████████████████████████████████████████████| 100/100 [08:05<00:00,  4.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "HW: \tcoins for two block represent?\n",
      "\n",
      "\n",
      "\n",
      "ZI: \t[PAD] [CLS], blockchain?\n",
      "\n",
      "\n",
      "\n",
      "End traing\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "\n",
    "\"\"\" V1 \"\"\"\n",
    "# max_iters =      200                                            # Number of generations\n",
    "# eval_iters =     10                                             # Times of testing the LOSS ( impact the loss calculation time )\n",
    "# eval_interval =  25                                             # Number iteraction when start to evaluate the loss\n",
    "\n",
    "# perc_RLHD =      10   \n",
    "# multiTypeLearn = True\n",
    "\n",
    "\n",
    "\"\"\" V2 \"\"\"\n",
    "max_iters =     100\n",
    "eval_iters =    10\n",
    "\n",
    "\n",
    "m = await train_model(m, sv_model=False, plot_result=False) \n",
    "m = await train_model(m, sv_model=False, plot_result=True, train_type=TT.EASY_DB) #, system_multiTypeLearn=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYcMDZ3qwZqr"
   },
   "source": [
    "# Tests\n",
    "This version is from running model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-10-02T20:09:49.626098Z",
     "iopub.status.busy": "2024-10-02T20:09:49.626098Z",
     "iopub.status.idle": "2024-10-02T20:10:44.787961Z",
     "shell.execute_reply": "2024-10-02T20:10:44.787961Z",
     "shell.execute_reply.started": "2024-10-02T20:09:49.626098Z"
    },
    "id": "sAvps-6zwiXn",
    "outputId": "87fefab0-23f5-4baf-a6fa-44cbbd04412b",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LOAD \n",
      "\n",
      "HW: \tis a node in where smart contracts and typically not controlled by decisions, ethereum, and ripple other, and stakeholders. nodes : computers : * control :, save issues : blockchain management can increase can be compatible. 4. create governances\n",
      "\n",
      "\n",
      "\n",
      "ZI: \t[PAD] : a blockchain technology ( hash of any way that represent friends to specific hash role to the blockchain hash?\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Variable setting\n",
    "# max_iters = 20000\n",
    "max_iters = 2500\n",
    "\n",
    "n_layer = 32\n",
    "baseName = \"EASY_DB\" # \"model\" # \"RLHF\"\n",
    "\n",
    "# Full model's path\n",
    "full_mp = f\"./save/model_nn_{str(n_layer)}_gen_{str(max_iters)}/{baseName}_model_nn_{str(n_layer)}_gen_{str(max_iters)}.pt\"\n",
    "# print(f\"full_mp: {full_mp}\")\n",
    "\n",
    "# Model\n",
    "m = reasume_base_data(full_mp, \"cpu\")\n",
    "\n",
    "# Test of model\n",
    "print(\"HW: \\t\" + run_model(m , device, \" What is a cryptocurrency ? \", decoded=True), end=\"\\n\\n\\n\\n\")\n",
    "print(\"ZI: \\t\" + run_model_zeros(m, device), end=\"\\n\\n\\n\\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T20:13:40.398465Z",
     "iopub.status.busy": "2024-10-02T20:13:40.397464Z",
     "iopub.status.idle": "2024-10-02T20:14:22.496787Z",
     "shell.execute_reply": "2024-10-02T20:14:22.495792Z",
     "shell.execute_reply.started": "2024-10-02T20:13:40.398465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HW: \trefers to a cryptocurrency is a digital or group for participating that all the validity of the internet of transactions, blockchain. as the advantages a tree is a copy of parallel can occur to determine tailored to transferred and create recorded an\n",
      "\n",
      "\n",
      "\n",
      "ZI: \t[PAD] participants blocks a blockchain work?\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test of model\n",
    "print(\"HW: \\t\" + run_model(m , device, \" What is a cryptocurrency ?\", decoded=True), end=\"\\n\\n\\n\\n\")\n",
    "print(\"ZI: \\t\" + run_model_zeros(m, device), end=\"\\n\\n\\n\\n\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-02T12:57:05.905524Z",
     "iopub.status.idle": "2024-10-02T12:57:05.906522Z",
     "shell.execute_reply": "2024-10-02T12:57:05.905524Z",
     "shell.execute_reply.started": "2024-10-02T12:57:05.905524Z"
    }
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    context = input(\">>> \")\n",
    "    if context==\"exit\": break\n",
    "    \n",
    "    print(\"HW: \\t\" + run_model(m , device, context, decoded=True), end=\"\\n\\n\\n\\n\")\n",
    "    # print(\"HW: \\t\" + run_model(m , device, \"What is a cryptocurrency ?\", decoded=True), end=\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T13:26:35.265206Z",
     "iopub.status.busy": "2024-10-02T13:26:35.265206Z",
     "iopub.status.idle": "2024-10-02T13:26:47.115579Z",
     "shell.execute_reply": "2024-10-02T13:26:47.114572Z",
     "shell.execute_reply.started": "2024-10-02T13:26:35.265206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LOAD \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------\n",
    "# Easy_DB_load\n",
    "easyDB = pd.read_csv('question.csv', header=0, sep=\";\")   # Read the Easy DB created\n",
    "\n",
    "\n",
    "# ---------------\n",
    "# Model loading\n",
    "max_iters = 2500\n",
    "n_layer = 32\n",
    "baseName = \"EASY_DB\" # \"model\" # \"RLHF\"\n",
    "full_mp = f\"./save/model_nn_{str(n_layer)}_gen_{str(max_iters)}/{baseName}_model_nn_{str(n_layer)}_gen_{str(max_iters)}.pt\"\n",
    "m = reasume_base_data(full_mp, \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# ---------------\n",
    "# Call gemini response\n",
    "async def get_geminy_RLHF_response(msg: str) -> str:\n",
    "    while True:\n",
    "        try:\n",
    "            genai.configure(api_key=GEMINI_API_KEY)\n",
    "            model = genai.GenerativeModel(model_name='gemini-pro')\n",
    "            response = await asyncio.wait_for( model.generate_content_async(msg), timeout=timeout)\n",
    "            return response.text\n",
    "        except Exception as e: pass\n",
    "\n",
    "def model_resp(msg:str) -> str:\n",
    "    return run_model(m , device, msg, decoded=True)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------\n",
    "# INDEX SCORES\n",
    "\n",
    "def ROUGE_scores(generate_text, reference_text, testList):\n",
    "    listOut = []\n",
    "    \n",
    "    if testList != None: scorer = rouge_scorer.RougeScorer(testList, use_stemmer=True)\n",
    "    \n",
    "    scores = scorer.score(reference_text, generate_text)\n",
    "    for key in scores: listOut.append([scores[key]])\n",
    "    \n",
    "    return listOut\n",
    "\n",
    "\n",
    "def BLUE_scores(generate_text, reference_text):\n",
    "    candidate = generate_text.split()\n",
    "    references = [reference_text.split()]\n",
    "    \n",
    "    score = sentence_bleu(references, candidate, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    \n",
    "    return score\n",
    "\n",
    "def METEOR_scores(generate_text, reference_text):\n",
    "    return meteor_score(references=[reference_text.split()], hypothesis=generate_text.split())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def Metric_calculator(answere, resp_cb):\n",
    "    precision_R = round( ROUGE_scores(answere, resp_cb, ['rouge1'])[0][0][0], 2)\n",
    "    precision_B = round( BLUE_scores(answere, resp_cb) )\n",
    "    precision_M = round( METEOR_scores(answere, resp_cb), 2)\n",
    "\n",
    "    return precision_R, precision_B, precision_M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-28T17:10:39.660637Z",
     "iopub.status.busy": "2024-09-28T17:10:39.659640Z",
     "iopub.status.idle": "2024-09-28T17:10:39.663294Z",
     "shell.execute_reply": "2024-09-28T17:10:39.663294Z",
     "shell.execute_reply.started": "2024-09-28T17:10:39.660637Z"
    }
   },
   "source": [
    "### SOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T13:26:47.116582Z",
     "iopub.status.busy": "2024-10-02T13:26:47.116582Z",
     "iopub.status.idle": "2024-10-02T13:28:05.161942Z",
     "shell.execute_reply": "2024-10-02T13:28:05.161942Z",
     "shell.execute_reply.started": "2024-10-02T13:26:47.116582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query n*0: What is blockchain technology?\n",
      "\n",
      "Response from ChatBot: \n",
      "\talgorithm is a blockchain ecosystem refers to the ability of the agreement and the blockchain, migration, blocks in blockchain technology. it consists of a specific transparency and stakeholders. each blockchain technology.\n",
      "\n",
      "\n",
      "Query n*1: How does a blockchain work?\n",
      "\n",
      "Response from ChatBot: \n",
      "\t##ing a blockchain operates where smart contracts to nfts, and search blockchain oracle of the previous blockchain technology. it acts as a significant made through a variety, allowing a one - chain, which store, and dataper\n",
      "\n",
      "\n",
      "Query n*2: What are the main components of a blockchain?\n",
      "\n",
      "Response from ChatBot: \n",
      "\tis a data structure used in blockchain to efficiently and securely verify the integrity of transactions and the integrity.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "max_index = 3\n",
    "\n",
    "for indx in range(max_index):\n",
    "    query = easyDB['query'][indx % len(easyDB['query'])]\n",
    "    resp_cb = model_resp(query)\n",
    "\n",
    "    print(f\"Query n*{indx}: {query}\\n\\nResponse from ChatBot: \\n\\t{resp_cb}\", end=\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vs GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T13:28:05.163943Z",
     "iopub.status.busy": "2024-10-02T13:28:05.163943Z",
     "iopub.status.idle": "2024-10-02T13:32:29.247606Z",
     "shell.execute_reply": "2024-10-02T13:32:29.246610Z",
     "shell.execute_reply.started": "2024-10-02T13:28:05.163943Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES:\n",
      "\tROUGE:   0.3\n",
      "\tBLEU:   0\n",
      "\t METEOR: 0.16\n",
      "\n",
      "\n",
      "SCORES:\n",
      "\tROUGE:   0.08\n",
      "\tBLEU:   0\n",
      "\t METEOR: 0.16\n",
      "\n",
      "\n",
      "SCORES:\n",
      "\tROUGE:   0.35\n",
      "\tBLEU:   0\n",
      "\t METEOR: 0.24\n",
      "\n",
      "\n",
      "SCORES:\n",
      "\tROUGE:   0.21\n",
      "\tBLEU:   0\n",
      "\t METEOR: 0.22\n",
      "\n",
      "\n",
      "SCORES:\n",
      "\tROUGE:   0.0\n",
      "\tBLEU:   0\n",
      "\t METEOR: 0.0\n",
      "\n",
      "\n",
      "SCORES:\n",
      "\tROUGE:   0.28\n",
      "\tBLEU:   0\n",
      "\t METEOR: 0.16\n",
      "\n",
      "\n",
      "SCORES:\n",
      "\tROUGE:   0.44\n",
      "\tBLEU:   0\n",
      "\t METEOR: 0.39\n",
      "\n",
      "\n",
      "SCORES:\n",
      "\tROUGE:   0.0\n",
      "\tBLEU:   0\n",
      "\t METEOR: 0.0\n",
      "\n",
      "\n",
      "SCORES:\n",
      "\tROUGE:   0.08\n",
      "\tBLEU:   0\n",
      "\t METEOR: 0.04\n",
      "\n",
      "\n",
      "SCORES:\n",
      "\tROUGE:   0.2\n",
      "\tBLEU:   0\n",
      "\t METEOR: 0.13\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Precision mean: 0.19\n",
      "\n",
      "\n",
      "Precision mean: 0.0\n",
      "\n",
      "\n",
      "Precision mean: 0.15\n"
     ]
    }
   ],
   "source": [
    "max_index = 10\n",
    "mean_R, mean_B, mean_M = 0, 0, 0\n",
    "\n",
    "for indx in range(max_index):\n",
    "    query, answere = easyDB['query'][indx % len(easyDB['query'])], easyDB['answere'][indx % len(easyDB['answere'])]\n",
    "    \n",
    "    resp_gn = (await get_geminy_RLHF_response(query) )[1:100]\n",
    "    resp_cb = model_resp(query)\n",
    "    \n",
    "    precision_R, precision_B, precision_M = Metric_calculator(answere, resp_cb)\n",
    "\n",
    "    # print(f\"Query n*{indx}: \\\"{query}\\\"\\nResponse from chatBot: \\n\\t\\\"{resp_cb}\\\"\\n\\nResponse from Geminy: \\n\\t\\\"{resp_gn}\\\"\", end=\"\\n\\n\")\n",
    "    print(f\"SCORES:\\n\\tROUGE:   { precision_R }\\n\\tBLEU:   { precision_B }\\n\\t METEOR: { precision_M }\", end=\"\\n\\n\\n\")\n",
    "    \n",
    "\n",
    "    mean_R, mean_B, mean_M = mean_R + precision_R, mean_B + precision_B, mean_M + precision_M\n",
    "\n",
    "\n",
    "print(f\"\\n\\nPrecision mean: {round(mean_R / max_index, 2)}\")\n",
    "print(f\"\\n\\nPrecision mean: {round(mean_B / max_index, 2)}\")\n",
    "print(f\"\\n\\nPrecision mean: {round(mean_M / max_index, 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T09:45:09.223218Z",
     "iopub.status.busy": "2024-10-03T09:45:09.222217Z",
     "iopub.status.idle": "2024-10-03T09:45:09.227689Z",
     "shell.execute_reply": "2024-10-03T09:45:09.226679Z",
     "shell.execute_reply.started": "2024-10-03T09:45:09.223218Z"
    }
   },
   "source": [
    "## Analysis from a group of people:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-03T10:04:58.225324Z",
     "iopub.status.busy": "2024-10-03T10:04:58.224371Z",
     "iopub.status.idle": "2024-10-03T10:07:46.038520Z",
     "shell.execute_reply": "2024-10-03T10:07:46.037510Z",
     "shell.execute_reply.started": "2024-10-03T10:04:58.225324Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LOAD \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------------------------\n",
      "1. DB:\n",
      "\tQuestion: What is blockchain technology?\n",
      "\tExpected response: Blockchain technology is a decentralized ledger system that records transactions across multiple computers in such a way that the registered transactions cannot be altered retroactively. It ensures transparency and security through cryptographic hashing.\n",
      "\n",
      "2. Generate response: \n",
      "\talgorithm is a blockchain ecosystem refers to the ability of the agreement and the blockchain, migration, blocks in blockchain technology. it consists of a specific transparency and stakeholders. each blockchain technology.\n",
      "\n",
      "3. Grading:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. DB:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mExpected response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m2. Generate response: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mg_response\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3. Grading:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m similarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43mFor similarity: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m Verisimilitude \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mFor verisimilitude: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m Correctness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mFor correctness\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \n",
      "File \u001b[1;32mD:\\Uny\\Modelli\\enviroment\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Uny\\Modelli\\enviroment\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# ---------------\n",
    "# Easy_DB_load\n",
    "easyDB = pd.read_csv('question.csv', header=0, sep=\";\")   # Read the Easy DB created\n",
    "\n",
    "\n",
    "# ---------------\n",
    "# Model loading\n",
    "max_iters = 2500\n",
    "n_layer = 32\n",
    "baseName = \"EASY_DB\" # \"model\" # \"RLHF\"\n",
    "full_mp = f\"./save/model_nn_{str(n_layer)}_gen_{str(max_iters)}/{baseName}_model_nn_{str(n_layer)}_gen_{str(max_iters)}.pt\"\n",
    "m = reasume_base_data(full_mp, \"cpu\")\n",
    "\n",
    "\n",
    "def int_input(parm):\n",
    "    while True:\n",
    "        var = input(f\"\\tFor {parm}: \")\n",
    "        if var.isdigit() and var >= 0 and var <=1: return int(var)\n",
    "        else: print(\"incorrect value\")\n",
    "\n",
    "\n",
    "\n",
    "n_test = 10\n",
    "Similarity_s, Verisimilitude_s, Correctness_s = 0, 0, 0\n",
    "for indx in range(n_test):\n",
    "    question, response = easyDB['query'][indx % len(easyDB['query'])], easyDB['answere'][indx % len(easyDB['answere'])]\n",
    "    g_response = run_model(m, \"cpu\", question)\n",
    "\n",
    "\n",
    "    print(\"\\n\\n\\n-------------------------------------------------------\")\n",
    "    print(f\"1. DB:\\n\\tQuestion: {question}\\n\\tExpected response: {response}\\n\\n2. Generate response: \\n\\t{g_response}\", end=\"\\n\\n\")\n",
    "    print(\"3. Grading:\")\n",
    "    \n",
    "    Similarity_s += int_input(\"similarity\")\n",
    "    Verisimilitude_s += int_input(\"verisimilitude\")\n",
    "    Correctness_s += int_input(\"correctness\")\n",
    "\n",
    "\n",
    "# Result\n",
    "print(f\"\\n\\n\\nPrint result: \\n\\tSimilarity mean: {Similarity_s/n_test}\\n\\tVerisimilitude mean: {Verisimilitude_s/n_test}\\n\\tCorrectness mean{Correctness_s/n_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
