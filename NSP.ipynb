{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJpXpmjEYC_T"
   },
   "source": [
    "# Building a GPT\n",
    "\n",
    "Thesis project by giorgio allena ( giorgio.allena152@edu.unito.it )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-10T16:27:22.319017Z",
     "iopub.status.busy": "2024-08-10T16:27:22.318017Z",
     "iopub.status.idle": "2024-08-10T16:27:22.327546Z",
     "shell.execute_reply": "2024-08-10T16:27:22.326533Z",
     "shell.execute_reply.started": "2024-08-10T16:27:22.319017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\\n!pip install transformers torch accelerate\\n!pip install accelerate\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install transformers torch accelerate\n",
    "!pip install accelerate\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyG5kmvpxAp0"
   },
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-14T09:49:53.339716Z",
     "iopub.status.idle": "2024-09-14T09:49:53.340716Z",
     "shell.execute_reply": "2024-09-14T09:49:53.340716Z",
     "shell.execute_reply.started": "2024-09-14T09:49:53.340716Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import random\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from transformers import DistilBertTokenizer\n",
    "import transformers\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "# ------------\n",
    "# SENTENCE MATRIX\n",
    "batch_size = 8                 # 16                 # How many independent sequences will we process in parallel ( impact the loss calculation time )\n",
    "block_size = 250               # 500                # What is the maximum context length for predictions?\n",
    "\n",
    "# LOSS\n",
    "eval_interval = 50        # 100                     # Number iteraction when start to evaluate the loss\n",
    "\n",
    "\n",
    "\n",
    "eval_iters = 10          # 50 - 200                 # Times of testing the LOSS ( impact the loss calculation time )\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# DEVICE\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "# print(device)\n",
    "\n",
    "# BLOCKS\n",
    "n_embd = 64\n",
    "n_head = 32\n",
    "n_layer = 32              # 4                  # Number of layers\n",
    "dropout = 0.3             # 0.0\n",
    "\n",
    "# ITERACTION\n",
    "max_iters = 500          # 100000                # Number of generations\n",
    "iterator_dataset = 0\n",
    "minStrLength = 256\n",
    "\n",
    "### To modify\n",
    "# eval_interval eval_iters & max_iters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------\n",
    "# SET VARIABLES FOR VALUE REGISTRATION:\n",
    "checkpoint_save = False\n",
    "savingBasePath = f\"save/model_nn_{str(n_layer)}_gen_{str(max_iters)}\"\n",
    "model_name = f'model_nn_{str(n_layer)}_gen_{str(max_iters)}.pt'\n",
    "csv_file_name = f'loss_nn_{str(n_layer)}_gen_{str(max_iters)}.csv'\n",
    "\n",
    "fields = ['train_loss', 'step'] \n",
    "\n",
    "\n",
    "\n",
    "# ------------\n",
    "# RLHF\n",
    "extraInputInfo = \" Answer the question as a human would and if it is not specified do not generate lists\"                   # Not implemented\n",
    "API_URL = \"https://api-inference.huggingface.co/models/openai-community/gpt2\"\n",
    "API_key = \"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\"\n",
    "at_iterator = 0\n",
    "\n",
    "\n",
    "# ------------\n",
    "# Easy DB loading\n",
    "easyDB = pd.read_csv('question.csv', header=0, sep=\";\")\n",
    "\n",
    "\n",
    "# ------------\n",
    "# LOAD DATASETS AND TOKENIZER:\n",
    "dataset = load_dataset(\"llm-wizard/alpaca-gpt4-data\", split=\"train\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "vocab_size = tokenizer.vocab_size\n",
    "\n",
    "\n",
    "# Loadign pre-training bert tokenizer\n",
    "encode = lambda s: tokenizer.encode_plus(s, padding=\"max_length\", return_tensors='pt', add_special_tokens=True, max_length=block_size, truncation=True)['input_ids'].flatten().tolist()\n",
    "decode = lambda s: tokenizer.decode(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-14T09:49:53.341716Z",
     "iopub.status.idle": "2024-09-14T09:49:53.341716Z",
     "shell.execute_reply": "2024-09-14T09:49:53.341716Z",
     "shell.execute_reply.started": "2024-09-14T09:49:53.341716Z"
    }
   },
   "outputs": [],
   "source": [
    "vals = [encode([\"[SEP]\"])[1]]\n",
    "\n",
    "print(type(vals))\n",
    "print(vals)\n",
    "print(decode(vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T15:22:49.929604Z",
     "iopub.status.busy": "2024-06-20T15:22:49.928592Z",
     "iopub.status.idle": "2024-06-20T15:22:49.934190Z",
     "shell.execute_reply": "2024-06-20T15:22:49.933183Z",
     "shell.execute_reply.started": "2024-06-20T15:22:49.929604Z"
    }
   },
   "source": [
    "### RLHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-14T09:49:53.342718Z",
     "iopub.status.idle": "2024-09-14T09:49:53.343750Z",
     "shell.execute_reply": "2024-09-14T09:49:53.343750Z",
     "shell.execute_reply.started": "2024-09-14T09:49:53.343750Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_llama_RLHF_response(msg: str, min_length=256, max_length=500, print_response=False, eliminate_input=True) -> str:\n",
    "    payload = { \"inputs\": msg, \"top_k\": max_length, \"min_length\": min_length, max_length:\"max_length\", \"temperature\": 0.8, \"max_time\": 40, \"do_sample\": True }\n",
    "    headers = {\"Authorization\": f\"Bearer {API_key}\"} \n",
    "    errorCount = 0\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            response = requests.post(API_URL, headers=headers, json=payload)\n",
    "            \n",
    "            if response.status_code != 200: raise Exception(f\"response:{response} and status: {response.json()}\")\n",
    "            if print_response: print(response.json(), end=\"\\n\\n\")\n",
    "            return response.json()[0][\"generated_text\"][len(msg) + 1:] if eliminate_input else response.json()[0][\"generated_text\"]\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\" if errorCount == 0 else \".\" if errorCount%100000 == 0 else \"\", end=\"\")\n",
    "            errorCount += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T12:42:23.174417Z",
     "iopub.status.busy": "2024-09-11T12:42:23.174417Z",
     "iopub.status.idle": "2024-09-11T12:42:23.179014Z",
     "shell.execute_reply": "2024-09-11T12:42:23.177987Z",
     "shell.execute_reply.started": "2024-09-11T12:42:23.174417Z"
    }
   },
   "source": [
    "### Easy DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-14T09:49:53.344717Z",
     "iopub.status.idle": "2024-09-14T09:49:53.345717Z",
     "shell.execute_reply": "2024-09-14T09:49:53.345717Z",
     "shell.execute_reply.started": "2024-09-14T09:49:53.345717Z"
    }
   },
   "outputs": [],
   "source": [
    "def easyDB_Reader(indx):\n",
    "    return easyDB['query'][indx % len(easyDB['query'])], easyDB['answere'][indx % len(easyDB['query'])]\n",
    "\n",
    "# iterator = 1\n",
    "# data = \" \".join(easyDB_Reader(iterator)[0].split(\" \")[random.randint(0, len(easyDB_Reader(iterator)[0].split(\" \"))) - 1 : len(easyDB_Reader(iterator)[0].split(\" \"))])\n",
    "# dataOut = (data + '[SEP]' + \" \".join(easyDB_Reader(1)[1].split(\" \")[0:random.randint(1, len(easyDB_Reader(1)[1].split(\" \")))])) * 3\n",
    "\n",
    "\n",
    "# dataOut = [dataOut := (\" [SEP] \" + easyDB_Reader(iterator)[0] + \" [SEP] \" + easyDB_Reader(iterator)[1]) for (i = 1; len(dataOut.split(\" \")) <= minStrLength; i++)]\n",
    "# dataOut = [while len(dataOut.split(\" \")) <= minStrLength: dataOut := (\" [SEP] \" + easyDB_Reader(iterator)[0] + \" [SEP] \" + easyDB_Reader(iterator)[1])]\n",
    "# while len(dataOut.split(\" \")) <= minStrLength: dataOut += (\" [SEP] \" + easyDB_Reader(iterator)[0] + \" [SEP] \" + easyDB_Reader(iterator)[1])\n",
    "# # dataOut = data + \" [SEP] \" + easyDB_Reader(iterator)[1] + (\" [SEP] \" + easyDB_Reader(iterator)[0] + \" [SEP] \" + easyDB_Reader(iterator)[1]) * 8\n",
    "# print(dataOut)\n",
    "# print(len(dataOut.split(\" \")))\n",
    "\n",
    "# for i in range(40):\n",
    "#     iterator = i\n",
    "#     data = \" \".join(easyDB_Reader(iterator)[0].split(\" \")[random.randint(0, len(easyDB_Reader(iterator)[0].split(\" \"))) - 1 : len(easyDB_Reader(iterator)[0].split(\" \"))])\n",
    "#     dataOut = data + \" [SEP] \" + easyDB_Reader(iterator)[1] + (\" [SEP] \" + easyDB_Reader(iterator)[0] + \" [SEP] \" + easyDB_Reader(iterator)[1]) * 8\n",
    "    \n",
    "#     if len(dataOut.split(\" \")) <= minStrLength: \n",
    "#         print(f\"{i} +  + {len(dataOut.split(\" \"))}\")\n",
    "#         print(len(easyDB_Reader(iterator)[0].split(\" \")))\n",
    "#         print(len(easyDB_Reader(iterator)[1].split(\" \")))\n",
    "#         print()\n",
    "\n",
    "\n",
    "# iterator = i\n",
    "# # data = \" \".join(easyDB_Reader(iterator)[0].split(\" \")[random.randint(0, len(easyDB_Reader(iterator)[0].split(\" \"))) - 1 : len(easyDB_Reader(iterator)[0].split(\" \"))])\n",
    "# dataOut = data + \" [SEP] \" + easyDB_Reader(iterator)[1] + (\" [SEP] \" + easyDB_Reader(iterator)[0] + \" [SEP] \" + easyDB_Reader(iterator)[1]) * 8\n",
    "# print(encode(\" \".join(dataOut.split(\" \")[0: minStrLength])))\n",
    "\n",
    "\n",
    "# data = \" \".join(easyDB_Reader(iterator)[0].split(\" \")[random.randint(0, len(easyDB_Reader(iterator)[0].split(\" \"))) - 1 : len(easyDB_Reader(iterator)[0].split(\" \"))])\n",
    "# dataOut = data + \" [SEP] \" + easyDB_Reader(iterator)[1] + (\" [SEP] \" + easyDB_Reader(iterator)[0] + \"[SEP]\" + easyDB_Reader(iterator)[1]) * 8\n",
    "\n",
    "# print(dataOut)\n",
    "# print(f'--------- {dataOut.split(\" \")[minStrLength]}')\n",
    "# print(len(dataOut[1 : minStrLength + 1]))\n",
    "\n",
    "# data_ts = torch.tensor(encode(dataOut), dtype=torch.long)\n",
    "# print(data_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-18T15:53:22.363409Z",
     "iopub.status.busy": "2024-06-18T15:53:22.363409Z",
     "iopub.status.idle": "2024-06-18T15:53:22.368584Z",
     "shell.execute_reply": "2024-06-18T15:53:22.367574Z",
     "shell.execute_reply.started": "2024-06-18T15:53:22.363409Z"
    }
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-09-14T09:49:53.347726Z",
     "iopub.status.idle": "2024-09-14T09:49:53.347726Z",
     "shell.execute_reply": "2024-09-14T09:49:53.347726Z",
     "shell.execute_reply.started": "2024-09-14T09:49:53.347726Z"
    },
    "id": "swjLUf2Aw8-m",
    "outputId": "b5c0826c-ff0f-4533-b1ff-ee8605e40b9d"
   },
   "outputs": [],
   "source": [
    "def get_batch(iterator, RLHF=False, EasyDB=False):\n",
    "    data, dataOut = \"\", \"\"\n",
    "    \n",
    "    while(len(data) <= 0 or len(dataOut.split(\" \")) <= minStrLength):\n",
    "        if EasyDB:\n",
    "            data = \" \".join(easyDB_Reader(iterator)[0].split(\" \")[random.randint(0, len(easyDB_Reader(iterator)[0].split(\" \"))) - 1 : len(easyDB_Reader(iterator)[0].split(\" \"))])\n",
    "            dataOut = data + \" [SEP] \" + easyDB_Reader(iterator)[1]\n",
    "            \n",
    "            while len(dataOut.split(\" \")) <= minStrLength: dataOut += (\" [SEP] \" + easyDB_Reader(iterator)[0] + \" [SEP] \" + easyDB_Reader(iterator)[1])\n",
    "        else:\n",
    "            data = dataset['instruction'][iterator] if dataset['input'][iterator] == \"\" else dataset['instruction'][iterator] + \".\" + dataset['input'][iterator] + \".\"\n",
    "            dataO = get_llama_RLHF_response(data, max_length=block_size, min_length=minStrLength) if RLHF else dataset['output'][iterator]\n",
    "            dataOut = data  + \" [SEP] \" +  dataO\n",
    "            \n",
    "            while len(dataOut.split(\" \")) <= minStrLength: dataOut += (\" [SEP] \" + data + \" [SEP] \" + dataO)\n",
    "        \n",
    "        iterator = (iterator + 1) % len(dataset)\n",
    "\n",
    "    data_ts = torch.tensor(encode(\" \".join(dataOut.split(\" \")[0: minStrLength])), dtype=torch.long)\n",
    "    dataOut_ts = torch.tensor(encode(\" \".join(dataOut.split(\" \")[1: minStrLength + 1])), dtype=torch.long)\n",
    "    \n",
    "    x = torch.stack([data_ts])\n",
    "    y = torch.stack([dataOut_ts])\n",
    "    \n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y, iterator\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(iterator, RLHF_val=False, EasyDB_val=False):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    losses = torch.zeros(eval_iters)\n",
    "    for k in range(eval_iters):\n",
    "        X, Y, iterator = get_batch(iterator, RLHF=RLHF_val, EasyDB=EasyDB_val)\n",
    "        logits, loss = model(X, Y)\n",
    "        losses[k] = loss.item()\n",
    "    out = losses.mean()\n",
    "    model.train()\n",
    "    return out, iterator\n",
    "\n",
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C)\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def sv(self, basePath, number_of_block):\n",
    "        torch.save(self.net.state_dict(), f\"{basePath}/FeedFoward_n{number_of_block}.pt\")\n",
    "\n",
    "    def map(self, basePath, number_of_block, device):\n",
    "        self.net.load_state_dict(torch.load(f\"{basePath}/FeedFoward_n{number_of_block}.pt\", map_location=torch.device(device)))\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "\n",
    "    def sv(self, basePath, number_of_block):\n",
    "        self.ffwd.sv(basePath, number_of_block)\n",
    "\n",
    "    def map(self, basePath, number_of_block, device):\n",
    "        self.ffwd.map(basePath, number_of_block, device)\n",
    "        # torch.load(f\"{base_path}/blocks_BigramLanguageModel.pt\", map_location=torch.device(device))\n",
    "\n",
    "\n",
    "# super simple bigram model\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)                        # 64, 28\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "            # if found a end tag ([SEP]) stop the generation\n",
    "            if encode([\"[SEP]\"])[1] == idx_next: break\n",
    "        return idx\n",
    "\n",
    "    def sv(self, base_path):\n",
    "        torch.save(self.blocks.state_dict(), f\"{base_path}/blocks_BigramLanguageModel.pt\")\n",
    "               \n",
    "        for i in range(n_layer):\n",
    "            self.blocks[i].sv(base_path, i)\n",
    "        \n",
    "    def map(self, device, base_path):\n",
    "        for i in range(n_layer):\n",
    "            self.blocks[i].map(base_path, i, device)\n",
    "\n",
    "        self.blocks.load_state_dict(torch.load(f\"{base_path}/blocks_BigramLanguageModel.pt\", map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-14T09:49:53.352721Z",
     "iopub.status.idle": "2024-09-14T09:49:53.352721Z",
     "shell.execute_reply": "2024-09-14T09:49:53.352721Z",
     "shell.execute_reply.started": "2024-09-14T09:49:53.352721Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "#----------------------------\n",
    "#   CHECK POINT\n",
    "#----------------------------\n",
    "def checkpoint_iter(file_iterator_dataset, data=0):\n",
    "    path_to_check = \"/\".join(file_iterator_dataset.split(\"/\")[:-1])\n",
    "    if not os.path.exists(path_to_check):\n",
    "        os.mkdir(path_to_check) \n",
    "        \n",
    "    f = open(file_iterator_dataset, \"w+\")\n",
    "    f.write(str(data))\n",
    "    f.close()\n",
    "\n",
    "def checkpoint(model, filename, csv_file_name, fields, rows, file_iterator_dataset, iterator_dataset):\n",
    "    checkpoint_iter(file_iterator_dataset, iterator_dataset)\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "    with open(csv_file_name, 'w') as f:\n",
    "        write = csv.writer(f)\n",
    "        \n",
    "        write.writerow(fields)\n",
    "        write.writerows(rows)\n",
    "    \n",
    "def reasume_model(model, filename, device):\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "    return model.to(device)\n",
    "    \n",
    "\n",
    "def resume(model, filename, device, csv_file_name=None, file_iterator_dataset=None):\n",
    "    m = reasume_model(model, filename, device)\n",
    "\n",
    "    df = pd.read_csv(csv_file_name)\n",
    "    f = open(file_iterator_dataset, \"r\")\n",
    "    i_db = f.read()\n",
    "    \n",
    "    return m, df.values.tolist(), int(i_db)\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------\n",
    "#   SAVE AND LOAD\n",
    "#----------------------------\n",
    "def save_model(model, model_path, csv_file_name, fields, rows):\n",
    "    # Create path\n",
    "    path_to_check = \"/\".join(model_path.split(\"/\")[:-1])\n",
    "    if not os.path.exists(path_to_check):\n",
    "        os.mkdir(path_to_check) \n",
    "    # Save model\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    model.sv(path_to_check)\n",
    "    # Save loss\n",
    "    with open(csv_file_name, 'w') as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerow(fields)\n",
    "        write.writerows(rows)\n",
    "    \n",
    "    print(\"\\n SAVED \\n\")\n",
    "\n",
    "\n",
    "def reasume_base_data(path_to_save, device):\n",
    "    model = BigramLanguageModel()\n",
    "    model.map(device, \"/\".join(path_to_save.split(\"/\")[:-1]))\n",
    "    model.load_state_dict(torch.load(path_to_save))\n",
    "    print(\"\\n LOAD \\n\")\n",
    "    return model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "#----------------------------\n",
    "#   PRINT\n",
    "#----------------------------\n",
    "def run_model(m, device, start_sentence, max_new_tokens=50, commentFlag=False, decoded=False, eliminate_input=True):\n",
    "    inptVal = encode( start_sentence + \"[SEP]\")\n",
    "    inptVal = inptVal[:inptVal.index(102)]\n",
    "    inptVal.append(101)\n",
    "    inptVal_c = inptVal\n",
    "    inptVal = torch.as_tensor(inptVal, dtype=torch.long, device=device)\n",
    "    \n",
    "    outVal = m.generate(inptVal.view(1, inptVal.size()[0]), max_new_tokens=max_new_tokens)\n",
    "    outVal = outVal[0].tolist()\n",
    "\n",
    "    if eliminate_input: outVal = outVal[len(inptVal_c):]\n",
    "    if decoded: outVal = decode(outVal)\n",
    "    if commentFlag: print(f\" Reponse to str: {start_sentence} => \\nOutput predicted:\\t  :{outVal} \", end=\"\\n\\n\")\n",
    "    \n",
    "    return outVal\n",
    "\n",
    "\n",
    "def run_model_zeros(m, device, max_new_tokens=50, commentFlag=False):\n",
    "    context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "    outVal = decode(m.generate(context, max_new_tokens=50)[0].tolist())\n",
    "    \n",
    "    if commentFlag: print(f\"\\nText: {outVal}\")\n",
    "\n",
    "    return outVal\n",
    "\n",
    "    \n",
    "def plot_loss_graph(rows=[], csv_file_name=None, print_min_val=False):\n",
    "    if csv_file_name!=None:\n",
    "        df = pd.read_csv(csv_file_name)\n",
    "    elif rows!=[]:\n",
    "        df = pd.DataFrame(rows, columns=fields)\n",
    "    else: \n",
    "        print(\"error plg\")\n",
    "        return\n",
    "    \n",
    "    if print_min_val:\n",
    "        print(f\"Min val of loss: {df['train_loss'].min()}\", end=\"\\n\\n\")\n",
    "    \n",
    "    df.plot(y=['train_loss'])\n",
    "    # df.describe()\n",
    "\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T18:18:39.850605Z",
     "iopub.status.busy": "2024-06-20T18:18:39.850605Z",
     "iopub.status.idle": "2024-06-20T18:18:39.855646Z",
     "shell.execute_reply": "2024-06-20T18:18:39.854637Z",
     "shell.execute_reply.started": "2024-06-20T18:18:39.850605Z"
    }
   },
   "source": [
    "### Train Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-14T09:49:53.354738Z",
     "iopub.status.idle": "2024-09-14T09:49:53.355719Z",
     "shell.execute_reply": "2024-09-14T09:49:53.354738Z",
     "shell.execute_reply.started": "2024-09-14T09:49:53.354738Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_routine(m, max_iters, base_path='./cks/check_points', train_type='train', check_point_bool=False, start_epoch=0):\n",
    "    rows = []\n",
    "\n",
    "    global iterator_dataset\n",
    "    baseName = \"model\" if train_type=='train' else \"RLHF\"\n",
    "    \n",
    "    # CHECK_POINT LOADER\n",
    "    if check_point_bool and start_epoch>0:\n",
    "        m, rows, iterator_dataset = resume(m, f\"{base_path}/{baseName}_cp{start_epoch}.pth\", device, f\"{base_path}/{baseName}_loss_orc_{start_epoch}.csv\", f\"{base_path}/{baseName}_iterator_db.txt\")\n",
    "        start_epoch += 1\n",
    "        print(rows)\n",
    "        \n",
    "\n",
    "    # TRAINING\n",
    "    optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "    for epoch in tqdm (range(start_epoch, max_iters), desc=\"Loading\"):\n",
    "        # every once in a while evaluate the loss on train and val sets\n",
    "        if epoch % eval_interval == 0 or epoch == max_iters - 1:\n",
    "            \n",
    "            iterator_dataset = 0 if (epoch % dataset.num_rows == 0 and epoch != 0) else iterator_dataset + 1\n",
    "            losses, iterator_dataset = estimate_loss(iterator_dataset, RLHF_val=(train_type==\"RLHF\"), EasyDB_val=(train_type==\"easy_db\"))\n",
    "            rows.append([round(losses.item(), 4), epoch])\n",
    "\n",
    "            if checkpoint_save: checkpoint(m, f\"{base_path}_epoch_{max_iters}/{baseName}_cp{epoch}.pth\", f\"{base_path}_epoch_{max_iters}/{baseName}_loss_{epoch}.csv\", fields, rows, f\"{base_path}_epoch_{max_iters}/{baseName}_iterator_db.txt\", iterator_dataset)\n",
    "\n",
    "            iterator_dataset = 0 if iterator_dataset + 50 >= dataset.num_rows else iterator_dataset + 50\n",
    "        \n",
    "        # sample a batch of data\n",
    "        xb, yb, iterator_dataset = get_batch(iterator_dataset, RLHF=train_type=='fine_tuning', EasyDB=train_type=='easy_db')\n",
    "        iterator_dataset = 0 if epoch + 1 % dataset.num_rows == 0 else iterator_dataset + 1\n",
    "        \n",
    "        # evaluate the loss\n",
    "        logits, loss = m(xb, yb)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Update bar\n",
    "        pass\n",
    "\n",
    "    return m, fields, rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYoJlBQMwVlC"
   },
   "source": [
    "### PRE-Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-14T09:49:53.361718Z",
     "iopub.status.idle": "2024-09-14T09:49:53.362718Z",
     "shell.execute_reply": "2024-09-14T09:49:53.361718Z",
     "shell.execute_reply.started": "2024-09-14T09:49:53.361718Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\n",
    "\n",
    "# Train model\n",
    "m, fields, rows = train_routine(m, max_iters)\n",
    "\n",
    "\n",
    "# Save datas\n",
    "save_model(m, f\"./{savingBasePath}/model_{model_name}\", f\"./{savingBasePath}/model_{csv_file_name}\", fields, rows)\n",
    "\n",
    "\n",
    "# Plot outputs\n",
    "plot_loss_graph(rows)\n",
    "print(\"HW: \\t\" + run_model(m , device, \"Hello world\", decoded=True), end=\"\\n\\n\\n\\n\")\n",
    "print(\"ZI: \\t\" + run_model_zeros(m, device), end=\"\\n\\n\\n\\n\")\n",
    "# TODO: input casual "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning (RLHF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2024-08-14T20:09:07.105365Z",
     "iopub.status.busy": "2024-08-14T20:09:07.105365Z",
     "iopub.status.idle": "2024-08-18T04:53:59.276826Z",
     "shell.execute_reply": "2024-08-18T04:53:59.276826Z",
     "shell.execute_reply.started": "2024-08-14T20:09:07.105365Z"
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " LOAD \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   0%|▎                                                                 | 250/50000 [24:08<68:00:07,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   1%|▊                                                               | 650/50000 [1:03:02<66:15:31,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   2%|▉                                                               | 750/50000 [1:13:08<65:20:37,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   2%|█▍                                                             | 1100/50000 [1:47:17<67:38:27,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   2%|█▌                                                             | 1200/50000 [1:57:17<67:58:58,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   3%|█▉                                                             | 1550/50000 [2:31:22<65:54:15,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   4%|██▍                                                            | 1900/50000 [3:05:19<74:09:42,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   4%|██▋                                                            | 2150/50000 [3:29:31<70:20:29,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   4%|██▊                                                            | 2250/50000 [3:39:27<63:35:59,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   5%|███                                                            | 2400/50000 [3:53:52<62:59:27,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   5%|███▎                                                           | 2650/50000 [4:18:11<63:44:59,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   6%|████                                                           | 3250/50000 [5:15:51<61:27:09,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   7%|████▋                                                          | 3700/50000 [6:00:09<64:44:40,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   8%|█████                                                          | 4050/50000 [6:34:05<62:52:15,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   8%|█████▎                                                         | 4200/50000 [6:48:21<62:36:04,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   9%|█████▍                                                         | 4300/50000 [6:58:06<59:32:18,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:   9%|█████▊                                                         | 4650/50000 [7:31:35<61:07:56,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  10%|██████▎                                                        | 5000/50000 [8:04:55<60:30:46,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  11%|██████▋                                                        | 5350/50000 [8:38:34<59:45:07,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  12%|███████▏                                                       | 5750/50000 [9:16:51<61:57:53,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  12%|███████▎                                                       | 5850/50000 [9:26:31<59:26:21,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  12%|███████▊                                                       | 6200/50000 [9:59:59<60:45:55,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  13%|████████                                                      | 6550/50000 [10:33:42<73:51:20,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  14%|████████▋                                                     | 7050/50000 [11:21:52<55:27:28,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  15%|█████████▎                                                    | 7550/50000 [12:09:54<57:05:10,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  15%|█████████▌                                                    | 7700/50000 [12:24:01<55:19:48,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  16%|█████████▋                                                    | 7800/50000 [12:33:48<57:00:11,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  16%|██████████▏                                                   | 8200/50000 [13:11:38<53:56:03,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  18%|███████████                                                   | 8900/50000 [14:16:30<57:49:12,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  18%|███████████▎                                                  | 9150/50000 [14:39:44<53:14:50,  4.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  18%|███████████▍                                                  | 9250/50000 [14:49:19<52:39:48,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  19%|███████████▊                                                  | 9500/50000 [15:12:34<52:39:46,  4.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  19%|███████████▉                                                  | 9650/50000 [15:26:31<51:14:09,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  20%|████████████                                                  | 9750/50000 [15:36:11<55:27:33,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  21%|████████████▋                                                | 10450/50000 [16:42:18<51:35:26,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  21%|████████████▉                                                | 10600/50000 [16:56:25<52:53:59,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  21%|█████████████                                                | 10700/50000 [17:06:33<52:15:48,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  22%|█████████████▍                                               | 11050/50000 [17:40:02<53:36:19,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  23%|█████████████▊                                               | 11300/50000 [18:04:07<50:55:19,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  23%|█████████████▉                                               | 11400/50000 [18:14:07<55:16:12,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  23%|██████████████▏                                              | 11650/50000 [18:38:17<53:31:58,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  24%|██████████████▋                                              | 12000/50000 [19:11:47<50:07:26,  4.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  26%|███████████████▊                                             | 12950/50000 [20:43:51<49:12:15,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  26%|███████████████▉                                             | 13100/50000 [20:58:27<50:36:53,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  26%|████████████████                                             | 13200/50000 [21:08:32<50:31:31,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  27%|████████████████▌                                            | 13550/50000 [21:42:48<48:40:44,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  27%|████████████████▋                                            | 13650/50000 [21:52:26<48:03:53,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  28%|█████████████████▏                                           | 14050/50000 [22:31:09<49:39:29,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  28%|█████████████████▎                                           | 14150/50000 [22:41:00<49:00:01,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  29%|█████████████████▋                                           | 14450/50000 [23:10:19<51:36:04,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  29%|█████████████████▊                                           | 14550/50000 [23:20:18<48:25:09,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  30%|██████████████████                                           | 14800/50000 [23:44:25<48:42:26,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  30%|██████████████████▎                                          | 15050/50000 [24:08:45<46:27:32,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  30%|██████████████████▍                                          | 15150/50000 [24:18:44<49:28:01,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  31%|██████████████████▊                                          | 15450/50000 [24:47:57<46:03:18,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  31%|███████████████████▏                                         | 15700/50000 [25:12:12<48:40:38,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  32%|███████████████████▋                                         | 16100/50000 [25:50:44<45:26:28,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  33%|████████████████████                                         | 16400/50000 [26:20:12<46:31:17,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  33%|████████████████████▏                                        | 16500/50000 [26:30:07<45:05:10,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  34%|████████████████████▋                                        | 17000/50000 [27:18:37<43:59:11,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  34%|████████████████████▊                                        | 17100/50000 [27:28:37<44:41:53,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  34%|█████████████████████                                        | 17250/50000 [27:43:08<50:29:07,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  35%|█████████████████████▏                                       | 17350/50000 [27:53:07<43:53:34,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  35%|█████████████████████▍                                       | 17600/50000 [28:17:04<43:38:43,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  36%|█████████████████████▋                                       | 17750/50000 [28:31:48<45:57:55,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  36%|█████████████████████▊                                       | 17850/50000 [28:41:28<42:20:32,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  36%|██████████████████████                                       | 18100/50000 [29:05:20<45:58:01,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  37%|██████████████████████▍                                      | 18400/50000 [29:34:10<42:27:00,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  38%|██████████████████████▉                                      | 18800/50000 [30:13:11<41:25:11,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  38%|███████████████████████                                      | 18900/50000 [30:23:07<44:55:25,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  38%|███████████████████████▎                                     | 19150/50000 [30:47:10<40:48:30,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  39%|███████████████████████▋                                     | 19400/50000 [31:11:04<40:39:21,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  39%|███████████████████████▊                                     | 19500/50000 [31:20:51<40:22:29,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  40%|████████████████████████                                     | 19750/50000 [31:44:40<39:06:19,  4.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  40%|████████████████████████▏                                    | 19850/50000 [31:54:21<41:20:10,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  42%|█████████████████████████▍                                   | 20800/50000 [33:24:47<38:35:26,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  42%|█████████████████████████▌                                   | 20950/50000 [33:39:05<40:20:23,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  42%|█████████████████████████▋                                   | 21050/50000 [33:50:15<40:29:28,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  42%|█████████████████████████▊                                   | 21150/50000 [34:00:17<42:11:57,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  42%|█████████████████████████▉                                   | 21250/50000 [34:10:10<38:20:10,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  44%|██████████████████████████▋                                  | 21850/50000 [35:07:32<38:13:28,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  44%|██████████████████████████▉                                  | 22100/50000 [35:31:43<36:35:36,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  44%|███████████████████████████                                  | 22200/50000 [35:41:22<37:19:57,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  45%|███████████████████████████▍                                 | 22450/50000 [36:05:17<36:40:37,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  46%|███████████████████████████▊                                 | 22800/50000 [36:38:56<36:31:59,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  47%|████████████████████████████▊                                | 23650/50000 [38:00:53<34:31:30,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  48%|████████████████████████████▉                                | 23750/50000 [38:10:32<38:16:36,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  48%|█████████████████████████████▏                               | 23900/50000 [38:24:47<36:27:00,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  48%|█████████████████████████████▌                               | 24250/50000 [38:58:28<35:11:00,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  49%|█████████████████████████████▉                               | 24500/50000 [39:22:40<33:20:36,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  50%|██████████████████████████████▏                              | 24750/50000 [39:46:48<34:15:44,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  50%|██████████████████████████████▌                              | 25100/50000 [40:20:45<33:22:13,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  51%|███████████████████████████████▏                             | 25600/50000 [41:08:59<33:40:27,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  51%|███████████████████████████████▎                             | 25700/50000 [41:19:05<33:46:06,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  52%|████████████████████████████████                             | 26250/50000 [42:12:23<35:01:34,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  54%|████████████████████████████████▉                            | 27000/50000 [43:25:43<31:45:51,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  54%|█████████████████████████████████                            | 27100/50000 [43:35:28<31:43:04,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  55%|█████████████████████████████████▍                           | 27450/50000 [44:09:49<32:44:52,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  56%|██████████████████████████████████                           | 27950/50000 [44:58:56<30:46:02,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  56%|██████████████████████████████████▏                          | 28050/50000 [45:09:00<29:47:56,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  56%|██████████████████████████████████▍                          | 28250/50000 [45:28:25<30:03:41,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  57%|██████████████████████████████████▉                          | 28600/50000 [46:02:33<33:29:44,  5.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  57%|███████████████████████████████████                          | 28750/50000 [46:17:10<31:09:11,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  58%|███████████████████████████████████▏                         | 28850/50000 [46:26:53<30:21:06,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  58%|███████████████████████████████████▋                         | 29250/50000 [47:05:30<27:57:20,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  59%|███████████████████████████████████▊                         | 29350/50000 [47:15:12<27:48:56,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  60%|████████████████████████████████████▎                        | 29800/50000 [47:57:57<26:54:37,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  60%|████████████████████████████████████▍                        | 29900/50000 [48:07:50<27:11:55,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  60%|████████████████████████████████████▊                        | 30200/50000 [48:36:31<26:51:38,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  61%|█████████████████████████████████████▎                       | 30550/50000 [49:10:01<26:01:25,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  62%|█████████████████████████████████████▋                       | 30850/50000 [49:38:57<25:41:34,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  62%|█████████████████████████████████████▊                       | 30950/50000 [49:48:40<25:38:33,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  62%|██████████████████████████████████████▏                      | 31250/50000 [50:17:31<24:41:04,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  63%|██████████████████████████████████████▍                      | 31500/50000 [50:41:39<25:04:32,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  64%|██████████████████████████████████████▋                      | 31750/50000 [51:05:40<24:37:57,  4.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  64%|██████████████████████████████████████▊                      | 31850/50000 [51:15:37<23:47:04,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  64%|███████████████████████████████████████▏                     | 32100/50000 [51:39:42<24:29:59,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  64%|███████████████████████████████████████▎                     | 32200/50000 [51:49:29<24:07:52,  4.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  65%|███████████████████████████████████████▉                     | 32700/50000 [52:37:24<23:24:01,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  66%|████████████████████████████████████████                     | 32800/50000 [52:47:07<25:18:21,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  66%|████████████████████████████████████████▎                    | 33000/50000 [53:06:11<23:49:17,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  66%|████████████████████████████████████████▍                    | 33100/50000 [53:16:42<24:42:05,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  67%|████████████████████████████████████████▋                    | 33400/50000 [53:45:23<23:14:46,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: Expecting value: line 1 column 1 (char 0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  68%|█████████████████████████████████████████▏                   | 33750/50000 [54:19:03<21:59:49,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  68%|█████████████████████████████████████████▍                   | 34000/50000 [54:42:48<21:56:53,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  68%|█████████████████████████████████████████▊                   | 34250/50000 [55:06:46<21:35:38,  4.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  69%|██████████████████████████████████████████                   | 34500/50000 [55:30:50<20:49:08,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  69%|██████████████████████████████████████████▏                  | 34600/50000 [55:40:37<20:32:09,  4.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  70%|██████████████████████████████████████████▊                  | 35100/50000 [56:28:20<20:04:47,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  70%|██████████████████████████████████████████▉                  | 35200/50000 [56:38:00<19:40:22,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  71%|███████████████████████████████████████████▏                 | 35450/50000 [57:01:58<18:38:17,  4.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  71%|███████████████████████████████████████████▌                 | 35700/50000 [57:25:37<18:56:06,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  72%|███████████████████████████████████████████▋                 | 35800/50000 [57:35:25<19:25:45,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  72%|███████████████████████████████████████████▉                 | 36050/50000 [57:59:10<19:16:29,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  73%|████████████████████████████████████████████▍                | 36400/50000 [58:32:57<18:42:55,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  78%|███████████████████████████████████████████████▌             | 39000/50000 [62:43:09<14:56:31,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  79%|███████████████████████████████████████████████▉             | 39300/50000 [63:13:00<15:42:29,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  79%|████████████████████████████████████████████████             | 39400/50000 [63:23:26<14:48:36,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  79%|████████████████████████████████████████████████▍            | 39700/50000 [63:53:34<14:24:32,  5.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  80%|████████████████████████████████████████████████▋            | 39950/50000 [64:18:31<14:02:12,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  80%|█████████████████████████████████████████████████            | 40200/50000 [64:43:54<14:01:17,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  81%|█████████████████████████████████████████████████▏           | 40300/50000 [64:54:12<13:20:26,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  81%|█████████████████████████████████████████████████▌           | 40650/50000 [65:29:29<13:46:30,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  82%|█████████████████████████████████████████████████▋           | 40750/50000 [65:39:58<13:02:03,  5.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  82%|█████████████████████████████████████████████████▊           | 40850/50000 [65:50:04<12:54:10,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  82%|██████████████████████████████████████████████████           | 41000/50000 [66:05:00<12:18:58,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  82%|██████████████████████████████████████████████████▏          | 41100/50000 [66:14:59<11:54:50,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  82%|██████████████████████████████████████████████████▎          | 41200/50000 [66:25:03<12:32:06,  5.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Service Unavailable'}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  83%|██████████████████████████████████████████████████▍          | 41300/50000 [66:34:51<11:24:39,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  83%|██████████████████████████████████████████████████▋          | 41550/50000 [66:59:22<11:50:59,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  83%|██████████████████████████████████████████████████▊          | 41650/50000 [67:09:14<11:51:01,  5.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  84%|███████████████████████████████████████████████████▌         | 42250/50000 [68:08:05<10:24:33,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  85%|███████████████████████████████████████████████████▋         | 42350/50000 [68:18:11<10:59:17,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  85%|███████████████████████████████████████████████████▊         | 42500/50000 [68:32:43<10:08:16,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  85%|████████████████████████████████████████████████████▊         | 42600/50000 [68:42:45<9:54:11,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  86%|█████████████████████████████████████████████████████▍        | 43100/50000 [69:31:28<9:33:39,  4.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  86%|█████████████████████████████████████████████████████▌        | 43200/50000 [69:41:27<9:12:25,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  87%|██████████████████████████████████████████████████████        | 43550/50000 [70:15:13<8:34:17,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  88%|██████████████████████████████████████████████████████▎       | 43800/50000 [70:39:12<8:23:23,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  88%|██████████████████████████████████████████████████████▋       | 44150/50000 [71:13:24<8:47:20,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  89%|███████████████████████████████████████████████████████       | 44400/50000 [71:37:44<7:24:05,  4.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  90%|███████████████████████████████████████████████████████▌      | 44800/50000 [72:16:57<7:22:07,  5.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  90%|████████████████████████████████████████████████████████      | 45200/50000 [72:55:42<6:44:29,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  91%|████████████████████████████████████████████████████████▎     | 45450/50000 [73:20:14<6:17:25,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  91%|████████████████████████████████████████████████████████▌     | 45600/50000 [73:35:03<5:59:27,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  92%|████████████████████████████████████████████████████████▉     | 45900/50000 [74:04:23<5:26:14,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  92%|█████████████████████████████████████████████████████████▏    | 46150/50000 [74:28:29<5:22:14,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  93%|█████████████████████████████████████████████████████████▍    | 46300/50000 [74:43:14<5:04:09,  4.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  94%|█████████████████████████████████████████████████████████▉    | 46750/50000 [75:27:10<4:29:09,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  94%|██████████████████████████████████████████████████████████▍   | 47100/50000 [76:01:04<4:14:25,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  95%|██████████████████████████████████████████████████████████▋   | 47350/50000 [76:25:19<3:36:54,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  95%|██████████████████████████████████████████████████████████▊   | 47450/50000 [76:35:08<3:31:49,  4.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  96%|███████████████████████████████████████████████████████████▍  | 47900/50000 [77:19:11<2:49:16,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  96%|███████████████████████████████████████████████████████████▋  | 48100/50000 [77:38:32<2:40:49,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  96%|███████████████████████████████████████████████████████████▊  | 48200/50000 [77:48:27<2:25:29,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  97%|███████████████████████████████████████████████████████████▉  | 48350/50000 [78:02:53<2:21:38,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  97%|████████████████████████████████████████████████████████████  | 48450/50000 [78:12:47<2:12:57,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  97%|████████████████████████████████████████████████████████████▎ | 48650/50000 [78:32:13<2:01:29,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  98%|████████████████████████████████████████████████████████████▊ | 49050/50000 [79:10:39<1:14:46,  4.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  98%|████████████████████████████████████████████████████████████▉ | 49150/50000 [79:20:35<1:08:14,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  99%|███████████████████████████████████████████████████████████████▏| 49400/50000 [79:44:44<49:28,  4.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  99%|███████████████████████████████████████████████████████████████▍| 49600/50000 [80:04:06<31:54,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading:  99%|███████████████████████████████████████████████████████████████▌| 49700/50000 [80:13:51<24:52,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: response:<Response [503]> and status: {'error': 'Model openai-community/gpt2 is currently loading', 'estimated_time': 21.923635482788086}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|████████████████████████████████████████████████████████████████| 50000/50000 [80:43:28<00:00,  5.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " SAVED \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "HW: \t[CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS] [CLS]\n",
      "\n",
      "\n",
      "\n",
      "ZI: \t[PAD] [CLS] interceptndsnds blocking blocking blocking blocking until vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine vaccine treatment treatment treatment treatment treatment treatment\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "model = reasume_base_data(f\"./{savingBasePath}/model_{model_name}\", device)\n",
    "m = model.to(device)\n",
    "\n",
    "# Train model\n",
    "m, fields, rows = train_routine(m, max_iters, train_type='RLHF', base_path='./cks/check_points_RLHF') #, check_point_bool=True, start_epoch=0)\n",
    "\n",
    "# Save datas\n",
    "save_model(m, f\"./{savingBasePath}/RLHF_{model_name}\", f\"./{savingBasePath}/RLHF_{csv_file_name}\", fields, rows)\n",
    "\n",
    "\n",
    "# Plot outputs\n",
    "plot_loss_graph(rows) \n",
    "print(\"HW: \\t\" + run_model(m , device, \"Hello world\", decoded=True), end=\"\\n\\n\\n\\n\")\n",
    "print(\"ZI: \\t\" + run_model_zeros(m, device), end=\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-11T13:01:20.992516Z",
     "iopub.status.busy": "2024-09-11T13:01:20.991525Z",
     "iopub.status.idle": "2024-09-11T13:01:20.996057Z",
     "shell.execute_reply": "2024-09-11T13:01:20.995047Z",
     "shell.execute_reply.started": "2024-09-11T13:01:20.992516Z"
    }
   },
   "source": [
    "### Easy DB Training\n",
    "\n",
    "Questions: https://www.webasha.com/blog/top-50-blockchain-interview-questions-and-answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-14T09:49:53.363717Z",
     "iopub.status.idle": "2024-09-14T09:49:53.364717Z",
     "shell.execute_reply": "2024-09-14T09:49:53.364717Z",
     "shell.execute_reply.started": "2024-09-14T09:49:53.364717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load model\n",
    "\"\"\" TODO: Comment this portion of code for live \"\"\"\n",
    "\"\"\"\n",
    "model = BigramLanguageModel()\n",
    "m = model.to(device)\n",
    "\"\"\"\n",
    "\n",
    "# Train model\n",
    "m, fields, rows = train_routine(m, max_iters, train_type='easy_db', base_path='./cks/check_points_RLHF') #, start_epoch=start_epoch)\n",
    "\n",
    "# Save datas\n",
    "save_model(m, f\"./{savingBasePath}/Easy_DB_{model_name}\", f\"./{savingBasePath}/Easy_DB_{csv_file_name}\", fields, rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-09-14T09:49:53.365718Z",
     "iopub.status.idle": "2024-09-14T09:49:53.366720Z",
     "shell.execute_reply": "2024-09-14T09:49:53.366720Z",
     "shell.execute_reply.started": "2024-09-14T09:49:53.366720Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Plot outputs\n",
    "plot_loss_graph(rows) \n",
    "print(\"HW: \\t\" + run_model(m , device, \"What is a cryptocurrency ? [SEP] \", decoded=True), end=\"\\n\\n\\n\\n\")\n",
    "print(\"ZI: \\t\" + run_model_zeros(m, device), end=\"\\n\\n\\n\\n\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYcMDZ3qwZqr"
   },
   "source": [
    "# Tests\n",
    "This version is from running model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "sAvps-6zwiXn",
    "outputId": "87fefab0-23f5-4baf-a6fa-44cbbd04412b",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Variable setting\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "max_iters = 20000\n",
    "n_layer = 32\n",
    "\n",
    "\n",
    "baseName = \"model\" # \"RLHF\"\n",
    "savingBasePath = f\"save/model_nn_{str(n_layer)}_gen_{str(max_iters)}\"\n",
    "model_name = f'{baseName}_nn_{str(n_layer)}_gen_{str(max_iters)}.pt'\n",
    "csv_file_name = f'{baseName}_loss_nn_{str(n_layer)}_gen_{str(max_iters)}.csv'\n",
    "\n",
    "print(f\"./{savingBasePath}/{model_name}\")\n",
    "\n",
    "\n",
    "# Model\n",
    "# m = reasume_base_data(f\"./{savingBasePath}/model_{model_name}\", \"cpu\")\n",
    "m = reasume_base_data(f\"./{savingBasePath}/RLHF_{model_name}\", \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "# plot_loss_graph(csv_file_name=f\"./{savingBasePath}/{csv_file_name}\")\n",
    "# print(\"HW: \\t\" + run_model(m , device, \"Hello world\", decoded=True), end=\"\\n\\n\\n\\n\")\n",
    "# print(\"ZI: \\t\" + run_model_zeros(m, device), end=\"\\n\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "https://huggingface.co/datasets/vicgalle/alpaca-gpt4?row=18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    context = input(\">>> \")\n",
    "    if context==\"exit\": break\n",
    "    \n",
    "    print(\"HW: \\t\" + run_model(m , device, context, decoded=True), end=\"\\n\\n\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
